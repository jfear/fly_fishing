import sys
sys.path.insert(0, srcdir('../lcdb-wf'))
import os
from textwrap import dedent
import yaml
import tempfile
import pandas as pd
from lcdblib.snakemake import helpers, aligners
from lcdblib.utils import utils
from lib import common
from lib import cluster_specific
from lib.patterns_targets import RNASeqConfig

# ----------------------------------------------------------------------------
#
# Search for the string "NOTE:" to look for points of configuration that might
# be helpful for your experiment.
#
# ----------------------------------------------------------------------------

# Only use default if no configfile specified on the command line with
# --configfile
if not workflow.overwrite_configfile:
    configfile: 'config/config.yaml'
else:
    configfile: workflow.overwrite_configfile

include: '../references-wf/Snakefile'
shell.prefix('set -euo pipefail; export TMPDIR={};'.format(cluster_specific.tempdir_for_biowulf()))
shell.executable('/bin/bash')

config = common.load_config(config)

c = RNASeqConfig(config, config.get('patterns', 'config/rnaseq_patterns.yaml'))

wildcard_constraints:
    n = '[1,2]'


def wrapper_for(path):
    return 'file:' + os.path.join('../lcdb-wf','wrappers', 'wrappers', path)

# ----------------------------------------------------------------------------
# RULES
# ----------------------------------------------------------------------------

# See "patterns and targets" in the documentation for what's going on here.
final_targets = utils.flatten((
    utils.flatten(c.targets['salmon']),
))

# Special case: all samples are single-end
if all(c.sampletable.iloc[:, 0].apply(
    lambda x: not common.is_paired_end(c.sampletable, x))
):
    ALL_SE = True
    final_targets = [i.replace('{n}', '1') for i in final_targets]
else:
    ALL_SE = False

rule targets:
    """
    Final targets to create
    """
    input: final_targets

def render_r1_r2(pattern):
    if ALL_SE:
        return expand(pattern, sample='{sample}', n=[1])
    return expand(pattern, sample='{sample}', n=[1, 2])


# Convert the sampletable to be indexed by the first column, for
# convenience in generating the input/output filenames.
_st = c.sampletable.set_index(c.sampletable.columns[0])

rule fastq_dump:
    output:
        fastq=render_r1_r2(c.patterns['fastq'])
    run:
        srr = _st.loc[wildcards.sample, 'Run']

        # Two different paths depending on the layout. In both cases, we
        # want to avoid creating the final output until the very end, to
        # avoid incomplete downloads.
        if common.is_paired_end(c.sampletable, wildcards.sample):
            shell(
                'fastq-dump '
                '{srr} '
                '--gzip '
                '--split-files '
            )

            # The filenames are predictable, so we can move them as need.
            shell('mv {srr}_1.fastq.gz {output[0]}')
            shell('mv {srr}_2.fastq.gz {output[1]}')

        else:
            shell(
                'fastq-dump '
                '{srr} '
                '-Z '
                '| gzip -c > {output[0]}.tmp '
                '&& mv {output[0]}.tmp {output[0]} '
            )
            if not ALL_SE:
                shell('touch {output[1]}')


rule cutadapt:
    """
    Run cutadapt
    """
    input:
        fastq=common.fill_r1_r2(c.sampletable, c.patterns['fastq'])
    output:
        fastq=render_r1_r2(c.patterns['cutadapt'])
    log:
        render_r1_r2(c.patterns['cutadapt'])[0] + '.log'
    run:
        paired = len(input) == 2

        # NOTE: Change cutadapt params here
        extra='-a file:../lcdb-wf/include/adapters.fa -q 20 --minimum-length=25'

        if paired:
            shell(
                "cutadapt "
                "{extra} "
                "{input.fastq[0]} "
                "{input.fastq[1]} "
                "-o {output[0]} "
                "-p {output[1]} "
                "&> {log}"
            )
        else:
            shell(
                "cutadapt "
                "{extra} "
                "{input.fastq[0]} "
                "-o {output[0]} "
                "&> {log}"
            )
            if not ALL_SE:
                shell('touch {output[1]}')


# TODO add parameters to filename and pull those out using pattern matching.
rule salmon:
    """
    Quantify reads coming from transcripts with Salmon
    """
    input:
        fastq=common.fill_r1_r2(c.sampletable, c.patterns['cutadapt']),
        index=c.refdict[c.organism][config['salmon']['tag']]['salmon'],
    output:
        c.patterns['salmon']
    params:
        index_dir=os.path.dirname(c.refdict[c.organism][config['salmon']['tag']]['salmon']),
        outdir=os.path.dirname(c.patterns['salmon'])
    log:
        c.patterns['salmon'] + '.log'
    run:
        paired = len(input.fastq) == 2
        if paired:
            shell(
                # NOTE: adjust Salmon params as needed
                'salmon quant '
                '--index {params.index_dir} '
                '--output {params.outdir} '
                '--threads {threads} '

                # NOTE: --libType=A auto-detects library type. Change if needed.
                '--libType=A '

                # NOTE: Docs suggest using --gcBias and --seqBias is a good idea
                '--gcBias '
                '--seqBias '
                '-1 {input.fastq[0]} '
                '-2 {input.fastq[1]} '
                '&> {log}'
            )
        else:
            shell(
                # NOTE: adjust Salmon params as needed
                'salmon quant '
                '--index {params.index_dir} '
                '--output {params.outdir} '
                '--threads {threads} '

                # NOTE: --libType=A auto-detects library type. Change if needed.
                '--libType=A '

                # NOTE: Docs suggest using --gcBias and --seqBias is a good idea
                '--gcBias '
                '--seqBias '
                '-r {input.fastq} '
                '&> {log}'
            )


# TODO Add gff compare logic to compare different slmon outputs
# vim: ft=python
